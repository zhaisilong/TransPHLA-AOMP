{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 19961231\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hla_sequence = pd.read_csv('/home/chujunyi/5_ZY_MHC/data/common_hla_sequence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data(data):\n",
    "    pep_inputs, hla_inputs, labels = [], [], []\n",
    "    for pep, hla, label in zip(data.peptide, data.HLA_sequence, data.label):\n",
    "        pep, hla = pep.ljust(pep_max_len, '-'), hla.ljust(hla_max_len, '-')\n",
    "        pep_input = [[vocab[n] for n in pep]] # [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]\n",
    "        hla_input = [[vocab[n] for n in hla]]\n",
    "        pep_inputs.extend(pep_input)\n",
    "        hla_inputs.extend(hla_input)\n",
    "        labels.append(label)\n",
    "    return torch.LongTensor(pep_inputs), torch.LongTensor(hla_inputs), torch.LongTensor(labels)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, pep_inputs, hla_inputs, labels):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.pep_inputs = pep_inputs\n",
    "        self.hla_inputs = hla_inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self): # 样本数\n",
    "        return self.pep_inputs.shape[0] # 改成hla_inputs也可以哦！\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pep_inputs[idx], self.hla_inputs[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        '''\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    '''\n",
    "    seq_q: [batch_size, seq_len]\n",
    "    seq_k: [batch_size, seq_len]\n",
    "    seq_len could be src_len or it could be tgt_len\n",
    "    seq_len in seq_q and seq_len in seq_k maybe not equal\n",
    "    '''\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # [batch_size, 1, len_k], False is masked\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # [batch_size, len_q, len_k]\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "        \n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc(context) # [batch_size, len_q, d_model]\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        '''\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual) # [batch_size, seq_len, d_model]\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        '''\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        '''\n",
    "        enc_outputs = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "\n",
    "# ### Decoder\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, dec_self_attn_mask): # dec_inputs = enc_outputs\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        '''\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs) # [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attn\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "#         self.tgt_emb = nn.Embedding(d_model * 2, d_model)\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "        self.tgt_len = tgt_len\n",
    "        \n",
    "    def forward(self, dec_inputs): # dec_inputs = enc_outputs (batch_size, peptide_hla_maxlen_sum, d_model)\n",
    "        '''\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_intpus: [batch_size, src_len]\n",
    "        enc_outputs: [batsh_size, src_len, d_model]\n",
    "        '''\n",
    "#         dec_outputs = self.tgt_emb(dec_inputs) # [batch_size, tgt_len, d_model]\n",
    "        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device) # [batch_size, tgt_len, d_model]\n",
    "#         dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).cuda() # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_pad_mask = torch.LongTensor(np.zeros((dec_inputs.shape[0], tgt_len, tgt_len))).bool().to(device)\n",
    "\n",
    "        dec_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            dec_outputs, dec_self_attn = layer(dec_outputs, dec_self_attn_pad_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            \n",
    "        return dec_outputs, dec_self_attns\n",
    "\n",
    "\n",
    "# ### Transformer\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.pep_encoder = Encoder().to(device)\n",
    "        self.hla_encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.tgt_len = tgt_len\n",
    "        self.projection = nn.Sequential(\n",
    "                                        nn.Linear(tgt_len * d_model, 256),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        nn.BatchNorm1d(256),\n",
    "                                        nn.Linear(256, 64),\n",
    "                                        nn.ReLU(True),\n",
    "\n",
    "                                        #output layer\n",
    "                                        nn.Linear(64, 2)\n",
    "                                        ).to(device)\n",
    "        \n",
    "    def forward(self, pep_inputs, hla_inputs):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        '''\n",
    "        # tensor to store decoder outputs\n",
    "        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        \n",
    "        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        pep_enc_outputs, pep_enc_self_attns = self.pep_encoder(pep_inputs)\n",
    "        hla_enc_outputs, hla_enc_self_attns = self.hla_encoder(hla_inputs)\n",
    "        enc_outputs = torch.cat((pep_enc_outputs, hla_enc_outputs), 1) # concat pep & hla embedding\n",
    "        \n",
    "        # dec_outpus: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\n",
    "        dec_outputs, dec_self_attns = self.decoder(enc_outputs)\n",
    "        dec_outputs = dec_outputs.view(dec_outputs.shape[0], -1) # Flatten [batch_size, tgt_len * d_model]\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), pep_enc_self_attns, hla_enc_self_attns, dec_self_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performances(y_true, y_pred, y_prob, print_ = True):\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0, 1]).ravel().tolist()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    try:\n",
    "        mcc = ((tp*tn) - (fn*fp)) / np.sqrt(np.float((tp+fn)*(tn+fp)*(tp+fp)*(tn+fn)))\n",
    "    except:\n",
    "        print('MCC Error: ', (tp+fn)*(tn+fp)*(tp+fp)*(tn+fn))\n",
    "        mcc = np.nan\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    try:\n",
    "        recall = tp / (tp+fn)\n",
    "    except:\n",
    "        recall = np.nan\n",
    "        \n",
    "    try:\n",
    "        precision = tp / (tp+fp)\n",
    "    except:\n",
    "        precision = np.nan\n",
    "        \n",
    "    try: \n",
    "        f1 = 2*precision*recall / (precision+recall)\n",
    "    except:\n",
    "        f1 = np.nan\n",
    "        \n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    prec, reca, _ = precision_recall_curve(y_true, y_prob)\n",
    "    aupr = auc(reca, prec)\n",
    "    \n",
    "    if print_:\n",
    "        print('tn = {}, fp = {}, fn = {}, tp = {}'.format(tn, fp, fn, tp))\n",
    "        print('y_pred: 0 = {} | 1 = {}'.format(Counter(y_pred)[0], Counter(y_pred)[1]))\n",
    "        print('y_true: 0 = {} | 1 = {}'.format(Counter(y_true)[0], Counter(y_true)[1]))\n",
    "        print('auc={:.4f}|sensitivity={:.4f}|specificity={:.4f}|acc={:.4f}|mcc={:.4f}'.format(roc_auc, sensitivity, specificity, accuracy, mcc))\n",
    "        print('precision={:.4f}|recall={:.4f}|f1={:.4f}|aupr={:.4f}'.format(precision, recall, f1, aupr))\n",
    "    \n",
    "    return (roc_auc, accuracy, mcc, f1, sensitivity, specificity, precision, recall, aupr)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "def transfer(y_prob, threshold = 0.5):\n",
    "    return np.array([[0, 1][x > threshold] for x in y_prob])\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "f_mean = lambda l: sum(l)/len(l)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "def performances_to_pd(performances_list):\n",
    "    metrics_name = ['roc_auc', 'accuracy', 'mcc', 'f1', 'sensitivity', 'specificity', 'precision', 'recall', 'aupr']\n",
    "\n",
    "    performances_pd = pd.DataFrame(performances_list, columns = metrics_name)\n",
    "    performances_pd.loc['mean'] = performances_pd.mean(axis = 0)\n",
    "    performances_pd.loc['std'] = performances_pd.std(axis = 0)\n",
    "    \n",
    "    return performances_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    time_train_ep = 0\n",
    "    model.train()\n",
    "    y_true_train_list, y_prob_train_list = [], []\n",
    "    loss_train_list, dec_attns_train_list = [], []\n",
    "    for train_pep_inputs, train_hla_inputs, train_labels in tqdm(train_loader):\n",
    "        '''\n",
    "        pep_inputs: [batch_size, pep_len]\n",
    "        hla_inputs: [batch_size, hla_len]\n",
    "        train_outputs: [batch_size, 2]\n",
    "        '''\n",
    "        train_pep_inputs, train_hla_inputs, train_labels = train_pep_inputs.to(device), train_hla_inputs.to(device), train_labels.to(device)\n",
    "\n",
    "        t1 = time.time()\n",
    "        train_outputs, _, _, train_dec_self_attns = model(train_pep_inputs, \n",
    "                                                                                                        train_hla_inputs)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        time_train_ep += time.time() - t1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_true_train = train_labels.cpu().numpy()\n",
    "        y_prob_train = nn.Softmax(dim = 1)(train_outputs)[:, 1].cpu().detach().numpy()\n",
    "        \n",
    "        y_true_train_list.extend(y_true_train)\n",
    "        y_prob_train_list.extend(y_prob_train)\n",
    "        loss_train_list.append(train_loss)\n",
    "#         dec_attns_train_list.append(train_dec_self_attns)\n",
    "        \n",
    "    y_pred_train_list = transfer(y_prob_train_list, threshold)\n",
    "    ys_train = (y_true_train_list, y_pred_train_list, y_prob_train_list)\n",
    "    \n",
    "    print('Fold-{}****Train (Ep avg): Epoch-{}/{} | Loss = {:.4f} | Time = {:.4f} sec'.format(fold, epoch, epochs, f_mean(loss_train_list), time_train_ep))\n",
    "    metrics_train = performances(y_true_train_list, y_pred_train_list, y_prob_train_list, print_ = True)\n",
    "    \n",
    "    return ys_train, loss_train_list, metrics_train, time_train_ep#, dec_attns_train_list\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def eval_step(model, val_loader, fold, epoch, epochs, use_cuda = True):\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    torch.manual_seed(19961231)\n",
    "    torch.cuda.manual_seed(19961231)\n",
    "    with torch.no_grad():\n",
    "        loss_val_list, dec_attns_val_list = [], []\n",
    "        y_true_val_list, y_prob_val_list = [], []\n",
    "        for val_pep_inputs, val_hla_inputs, val_labels in tqdm(val_loader):\n",
    "            val_pep_inputs, val_hla_inputs, val_labels = val_pep_inputs.to(device), val_hla_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs, _, _, val_dec_self_attns = model(val_pep_inputs, val_hla_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            y_true_val = val_labels.cpu().numpy()\n",
    "            y_prob_val = nn.Softmax(dim = 1)(val_outputs)[:, 1].cpu().detach().numpy()\n",
    "\n",
    "            y_true_val_list.extend(y_true_val)\n",
    "            y_prob_val_list.extend(y_prob_val)\n",
    "            loss_val_list.append(val_loss)\n",
    "#             dec_attns_val_list.append(val_dec_self_attns)\n",
    "            \n",
    "        y_pred_val_list = transfer(y_prob_val_list, threshold)\n",
    "        ys_val = (y_true_val_list, y_pred_val_list, y_prob_val_list)\n",
    "        \n",
    "        print('Fold-{} ****Test  Epoch-{}/{}: Loss = {:.6f}'.format(fold, epoch, epochs, f_mean(loss_val_list)))\n",
    "        metrics_val = performances(y_true_val_list, y_pred_val_list, y_prob_val_list, print_ = True)\n",
    "    return ys_val, loss_val_list, metrics_val#, dec_attns_val_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_max_len = 15 # peptide; enc_input max sequence length\n",
    "hla_max_len = 34 # hla; dec_input(=dec_output) max sequence length\n",
    "tgt_len = pep_max_len + hla_max_len\n",
    "pep_max_len, hla_max_len\n",
    "\n",
    "vocab = np.load('Transformer_vocab_dict.npy', allow_pickle = True).item()\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "# Transformer Parameters\n",
    "d_model = 64  # Embedding Size\n",
    "d_ff = 512 # FeedForward dimension\n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "n_layers = 1  # number of Encoder of Decoder Layer\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 50\n",
    "threshold = 0.5\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_with_loader(type_ = 'train',fold = None,  batch_size = 1024):\n",
    "    if type_ != 'train' and type_ != 'val':\n",
    "        data = pd.read_csv('/home/chujunyi/5_ZY_MHC/Anthem/Dataset/{}_set.csv'.format(type_), index_col = 0)\n",
    "    elif type_ == 'train':\n",
    "        data = pd.read_csv('/home/chujunyi/5_ZY_MHC/Anthem/Dataset/train_data_fold{}.csv'.format(fold), index_col = 0)\n",
    "    elif type_ == 'val':\n",
    "        data = pd.read_csv('/home/chujunyi/5_ZY_MHC/Anthem/Dataset/val_data_fold{}.csv'.format(fold), index_col = 0)\n",
    "        \n",
    "    pep_inputs, hla_inputs, labels = make_data(data)\n",
    "    loader = Data.DataLoader(MyDataSet(pep_inputs, hla_inputs, labels), batch_size, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    return data, pep_inputs, hla_inputs, labels, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "independent_data, independent_pep_inputs, independent_hla_inputs, independent_labels, independent_loader = data_with_loader(type_ = 'independent',fold = None,  batch_size = batch_size)\n",
    "external_data, external_pep_inputs, external_hla_inputs, external_labels, external_loader = data_with_loader(type_ = 'external',fold = None,  batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Fold-0=====\n",
      "-----Generate data loader-----\n",
      "Fold-0 Label info: Train = Counter({0: 287329, 1: 287329}) | Val = Counter({0: 71837, 1: 71837})\n",
      "-----Compile model-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "dir_saver:  ./model/pHLAIformer/\n",
      "path_saver:  ./model/pHLAIformer/model_layer1_multihead1_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:07<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-1/2 | Loss = 0.2686 | Time = 32.2584 sec\n",
      "tn = 253356, fp = 33973, fn = 30060, tp = 257269\n",
      "y_pred: 0 = 283416 | 1 = 291242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/141 [00:00<00:07, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: 0 = 287329 | 1 = 287329\n",
      "auc=0.9562|sensitivity=0.8954|specificity=0.8818|acc=0.8886|mcc=0.7772\n",
      "precision=0.8834|recall=0.8954|f1=0.8893|aupr=0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-1/2: Loss = 0.220305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn = 65135, fp = 6702, fn = 5850, tp = 65987\n",
      "y_pred: 0 = 70985 | 1 = 72689\n",
      "y_true: 0 = 71837 | 1 = 71837\n",
      "auc=0.9708|sensitivity=0.9186|specificity=0.9067|acc=0.9126|mcc=0.8253\n",
      "precision=0.9078|recall=0.9186|f1=0.9132|aupr=0.9701\n",
      "****Saving model: Best epoch = 1 | 5metrics_Best_avg = 0.9055\n",
      "*****Path saver:  ./model/pHLAIformer/model_layer1_multihead1_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:08<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0****Train (Ep avg): Epoch-2/2 | Loss = 0.2103 | Time = 32.6500 sec\n",
      "tn = 262963, fp = 24366, fn = 23163, tp = 264166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/141 [00:00<00:16,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: 0 = 286126 | 1 = 288532\n",
      "y_true: 0 = 287329 | 1 = 287329\n",
      "auc=0.9727|sensitivity=0.9194|specificity=0.9152|acc=0.9173|mcc=0.8346\n",
      "precision=0.9156|recall=0.9194|f1=0.9175|aupr=0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-2/2: Loss = 0.207874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn = 65936, fp = 5901, fn = 5793, tp = 66044\n",
      "y_pred: 0 = 71729 | 1 = 71945\n",
      "y_true: 0 = 71837 | 1 = 71837\n",
      "auc=0.9741|sensitivity=0.9194|specificity=0.9179|acc=0.9186|mcc=0.8372\n",
      "precision=0.9180|recall=0.9194|f1=0.9187|aupr=0.9737\n",
      "****Saving model: Best epoch = 2 | 5metrics_Best_avg = 0.9121\n",
      "*****Path saver:  ./model/pHLAIformer/model_layer1_multihead1_fold0.pkl\n",
      "-----Optimization Finished!-----\n",
      "-----Evaluate Results-----\n",
      "*****Path saver:  ./model/pHLAIformer/model_layer1_multihead1_fold0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:38<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-2/2: Loss = 0.203746\n",
      "tn = 264167, fp = 23162, fn = 22635, tp = 264694\n",
      "y_pred: 0 = 286802 | 1 = 287856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/141 [00:00<00:08, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: 0 = 287329 | 1 = 287329\n",
      "auc=0.9748|sensitivity=0.9212|specificity=0.9194|acc=0.9203|mcc=0.8406\n",
      "precision=0.9195|recall=0.9212|f1=0.9204|aupr=0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:09<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold-0 ****Test  Epoch-2/2: Loss = 0.207874\n",
      "tn = 65936, fp = 5901, fn = 5793, tp = 66044\n",
      "y_pred: 0 = 71729 | 1 = 71945\n",
      "y_true: 0 = 71837 | 1 = 71837\n",
      "auc=0.9741|sensitivity=0.9194|specificity=0.9179|acc=0.9186|mcc=0.8372\n",
      "precision=0.9180|recall=0.9194|f1=0.9187|aupr=0.9737\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-16c427d290be>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0mys_res_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_res_train_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics_res_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meval_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mep_best\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# , train_res_attns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             \u001B[0mys_res_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_res_val_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics_res_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meval_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mep_best\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# , val_res_attns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m             \u001B[0mys_res_evaluation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_res_evaluation_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics_res_evaluation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meval_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluation_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mep_best\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# , evaluation_res_attns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m             \u001B[0mys_res_experimental\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_res_experimental_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics_res_experimental\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meval_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_eval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexperimental_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfold\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mep_best\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# , experimental_res_attns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'evaluation_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for n_heads in range(1, 6):\n",
    "    \n",
    "    ys_train_fold_dict, ys_val_fold_dict = {}, {}\n",
    "    train_fold_metrics_list, val_fold_metrics_list = [], []\n",
    "    independent_fold_metrics_list, external_fold_metrics_list, ys_independent_fold_dict, ys_external_fold_dict = [], [], {}, {}\n",
    "    attns_train_fold_dict, attns_val_fold_dict, attns_independent_fold_dict, attns_external_fold_dict = {}, {}, {}, {}\n",
    "    loss_train_fold_dict, loss_val_fold_dict, loss_independent_fold_dict, loss_external_fold_dict = {}, {}, {}, {}\n",
    "\n",
    "    for fold in range(5):\n",
    "        print('=====Fold-{}====='.format(fold))\n",
    "        print('-----Generate data loader-----')\n",
    "        train_data, train_pep_inputs, train_hla_inputs, train_labels, train_loader = data_with_loader(type_ = 'train', fold = fold,  batch_size = batch_size)\n",
    "        val_data, val_pep_inputs, val_hla_inputs, val_labels, val_loader = data_with_loader(type_ = 'val', fold = fold,  batch_size = batch_size)\n",
    "        print('Fold-{} Label info: Train = {} | Val = {}'.format(fold, Counter(train_data.label), Counter(val_data.label)))\n",
    "\n",
    "        print('-----Compile model-----')\n",
    "        model = Transformer().to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr = 1e-3)#, momentum = 0.99)\n",
    "\n",
    "        print('-----Train-----')\n",
    "        dir_saver = './model/pHLAIformer/'\n",
    "        path_saver = './model/pHLAIformer/model_layer{}_multihead{}_fold{}.pkl'.format(n_layers, n_heads, fold)\n",
    "        print('dir_saver: ', dir_saver)\n",
    "        print('path_saver: ', path_saver)\n",
    "\n",
    "        metric_best, ep_best = 0, -1\n",
    "        time_train = 0\n",
    "        for epoch in range(1, epochs + 1):\n",
    "\n",
    "            ys_train, loss_train_list, metrics_train, time_train_ep = train_step(model, train_loader, fold, epoch, epochs, use_cuda) # , dec_attns_train\n",
    "            ys_val, loss_val_list, metrics_val = eval_step(model, val_loader, fold, epoch, epochs, use_cuda) #, dec_attns_val\n",
    "\n",
    "            metrics_ep_avg = sum(metrics_val[:4])/4\n",
    "            if metrics_ep_avg > metric_best: \n",
    "                metric_best, ep_best = metrics_ep_avg, epoch\n",
    "                if not os.path.exists(dir_saver):\n",
    "                    os.makedirs(dir_saver)\n",
    "                print('****Saving model: Best epoch = {} | 5metrics_Best_avg = {:.4f}'.format(ep_best, metric_best))\n",
    "                print('*****Path saver: ', path_saver)\n",
    "                torch.save(model.eval().state_dict(), path_saver)\n",
    "\n",
    "            time_train += time_train_ep\n",
    "\n",
    "        print('-----Optimization Finished!-----')\n",
    "        print('-----Evaluate Results-----')\n",
    "        if ep_best >= 0:\n",
    "            print('*****Path saver: ', path_saver)\n",
    "            model.load_state_dict(torch.load(path_saver))\n",
    "            model_eval = model.eval()\n",
    "\n",
    "            ys_res_train, loss_res_train_list, metrics_res_train = eval_step(model_eval, train_loader, fold, ep_best, epochs, use_cuda) # , train_res_attns\n",
    "            ys_res_val, loss_res_val_list, metrics_res_val = eval_step(model_eval, val_loader, fold, ep_best, epochs, use_cuda) # , val_res_attns\n",
    "            ys_res_independent, loss_res_independent_list, metrics_res_independent = eval_step(model_eval, independent_loader, fold, ep_best, epochs, use_cuda) # , independent_res_attns\n",
    "            ys_res_external, loss_res_external_list, metrics_res_external = eval_step(model_eval, external_loader, fold, ep_best, epochs, use_cuda) # , external_res_attns\n",
    "\n",
    "            train_fold_metrics_list.append(metrics_res_train)\n",
    "            val_fold_metrics_list.append(metrics_res_val)\n",
    "            independent_fold_metrics_list.append(metrics_res_independent)\n",
    "            external_fold_metrics_list.append(metrics_res_external)\n",
    "\n",
    "            ys_train_fold_dict[fold], ys_val_fold_dict[fold], ys_independent_fold_dict[fold], ys_external_fold_dict[fold] = ys_res_train, ys_res_val, ys_res_independent, ys_res_external    \n",
    "#             attns_train_fold_dict[fold], attns_val_fold_dict[fold], attns_independent_fold_dict[fold], attns_external_fold_dict[fold] = train_res_attns, val_res_attns, independent_res_attns, external_res_attns   \n",
    "            loss_train_fold_dict[fold], loss_val_fold_dict[fold], loss_independent_fold_dict[fold], loss_external_fold_dict[fold] = loss_res_train_list, loss_res_val_list, loss_res_independent_list, loss_res_external_list  \n",
    "\n",
    "        print(\"Total training time: {:6.2f} sec\".format(time_train))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Independent set:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'performances_to_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-c538add997dc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'****Independent set:'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperformances_to_pd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindependent_fold_metrics_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'****External set:'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mperformances_to_pd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexternal_fold_metrics_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'****Train set:'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'performances_to_pd' is not defined"
     ]
    }
   ],
   "source": [
    "print('****Independent set:')\n",
    "print(performances_to_pd(independent_fold_metrics_list))\n",
    "print('****External set:')\n",
    "print(performances_to_pd(external_fold_metrics_list))\n",
    "print('****Train set:')\n",
    "print(performances_to_pd(train_fold_metrics_list))\n",
    "print('****Val set:')\n",
    "print(performances_to_pd(val_fold_metrics_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}